{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage.io import imread, imsave\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from skimage.transform import rotate\n",
    "from skimage.util import random_noise\n",
    "from skimage.filters import gaussian\n",
    "from scipy import ndimage\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ref: https://www.analyticsvidhya.com/blog/2019/12/image-augmentation-deep-learning-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import fetch_lfw_people\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Activation, Conv2D, MaxPool2D, AveragePooling2D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Flatten, Dense, BatchNormalization, Conv2D, MaxPool2D, Activation, MaxPooling2D, Dropout,AveragePooling2D, Flatten\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            image_name  lowhead_or_not\n",
      "0            7-118.png               1\n",
      "1              8-4.png               1\n",
      "2              9-1.png               1\n",
      "3              9-2.png               1\n",
      "4              9-4.png               1\n",
      "..                 ...             ...\n",
      "319  sample_168000.png               0\n",
      "320  sample_169000.png               0\n",
      "321  sample_170000.png               0\n",
      "322  sample_171000.png               0\n",
      "323  sample_172000.png               0\n",
      "\n",
      "[324 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# loading dataset\n",
    "data = pd.read_csv('lowhead_train_equal.csv')\n",
    "data.head()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 324/324 [00:11<00:00, 27.96it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((324, 500, 500, 3), (324,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading images\n",
    "import glob\n",
    "lowheads_vs_other = glob.glob('lowheadVsother/*.*')\n",
    "\n",
    "train_img = []\n",
    "for img_name in tqdm(data['image_name']):\n",
    "    img_name = 'lowheadVsother/'+img_name\n",
    "    for i in lowheads_vs_other:\n",
    "        if(i == img_name):\n",
    "            image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb')\n",
    "            image=np.array(image)\n",
    "            image = image/255\n",
    "            train_img.append(image)\n",
    "\n",
    "train_x = np.array(train_img)\n",
    "train_y = data['lowhead_or_not'].values\n",
    "train_x.shape, train_y.shape\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 259/259 [00:24<00:00, 10.51it/s]\n"
     ]
    }
   ],
   "source": [
    "final_train_data = []\n",
    "final_train_label = []\n",
    "for i in tqdm(range(train_x.shape[0])):\n",
    "    final_train_data.append(train_x[i])\n",
    "    final_train_data.append(rotate(train_x[i], angle=45, mode = 'wrap'))\n",
    "    final_train_data.append(np.fliplr(train_x[i]))\n",
    "    final_train_data.append(np.flipud(train_x[i]))\n",
    "    final_train_data.append(random_noise(train_x[i],var=0.2**2))\n",
    "    for j in range(5):\n",
    "        final_train_label.append(train_y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1295\n",
      "1295\n"
     ]
    }
   ],
   "source": [
    "len(final_train_label), len(final_train_data)\n",
    "final_train = np.array(final_train_data)\n",
    "final_train_label = np.array(final_train_label)\n",
    "print(len(final_train_label))\n",
    "print(len(final_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting training images into torch format\n",
    "final_train = final_train.reshape(1295, 3, 500, 500)\n",
    "final_train  = torch.from_numpy(np.asarray(final_train))\n",
    "final_train = final_train.float()\n",
    "\n",
    "# converting the target into torch format\n",
    "final_train_label = final_train_label.astype(int)\n",
    "final_train_label = torch.from_numpy(final_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting validation images into torch format\n",
    "val_x = val_x.reshape(65, 3, 500, 500)\n",
    "val_x  = torch.from_numpy(val_x)\n",
    "val_x = val_x.float()\n",
    "\n",
    "# converting the target into torch format\n",
    "val_y = val_y.astype(int)\n",
    "val_y = torch.from_numpy(val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "class Net(Module):   \n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.cnn_layers = Sequential(\n",
    "            # Defining a 2D convolution layer\n",
    "            Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
    "            ReLU(inplace=True),\n",
    "            # adding batch normalization\n",
    "            BatchNorm2d(32),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # adding dropout\n",
    "            Dropout(p=0.25),\n",
    "            # Defining another 2D convolution layer\n",
    "            Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            ReLU(inplace=True),\n",
    "            # adding batch normalization\n",
    "            BatchNorm2d(64),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # adding dropout\n",
    "            Dropout(p=0.25),\n",
    "            # Defining another 2D convolution layer\n",
    "            Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
    "            ReLU(inplace=True),\n",
    "            # adding batch normalization\n",
    "            BatchNorm2d(128),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # adding dropout\n",
    "            Dropout(p=0.25),\n",
    "            # Defining another 2D convolution layer\n",
    "            Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
    "            ReLU(inplace=True),\n",
    "            # adding batch normalization\n",
    "            BatchNorm2d(128),\n",
    "            MaxPool2d(kernel_size=2, stride=2),\n",
    "            # adding dropout\n",
    "            Dropout(p=0.25),\n",
    "        )\n",
    "\n",
    "        self.linear_layers = Sequential(\n",
    "            Linear(128 * 31 * 31, 512), #25088\n",
    "            ReLU(inplace=True),\n",
    "            Dropout(),\n",
    "            Linear(512, 256),\n",
    "            ReLU(inplace=True),\n",
    "            Dropout(),\n",
    "            Linear(256,10),\n",
    "            ReLU(inplace=True),\n",
    "            Dropout(),\n",
    "            Linear(10,2)\n",
    "        )\n",
    "\n",
    "    # Defining the forward pass    \n",
    "    def forward(self, x):\n",
    "        x = self.cnn_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.linear_layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "Net(\n",
      "  (cnn_layers): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout(p=0.25, inplace=False)\n",
      "    (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Dropout(p=0.25, inplace=False)\n",
      "    (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Dropout(p=0.25, inplace=False)\n",
      "    (15): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (19): Dropout(p=0.25, inplace=False)\n",
      "  )\n",
      "  (linear_layers): Sequential(\n",
      "    (0): Linear(in_features=123008, out_features=512, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=256, out_features=10, bias=True)\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Dropout(p=0.5, inplace=False)\n",
      "    (9): Linear(in_features=10, out_features=2, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "## \n",
    "# defining the model\n",
    "model = Net()\n",
    "# defining the optimizer\n",
    "optimizer = Adam(model.parameters(), lr=0.000075)\n",
    "# defining the loss function\n",
    "criterion = CrossEntropyLoss()\n",
    "# checking if GPU is available\n",
    "\n",
    "\n",
    "device = torch.device('cpu' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)\n",
    "print()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.to(torch.device('cpu:0'))\n",
    "    criterion = criterion.cpu()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [04:57<00:00, 14.17s/it]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 1 \t training loss: \t 0.6998126819020226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [04:50<00:00, 13.83s/it]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 2 \t training loss: \t 0.5828504746868497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [04:53<00:00, 13.98s/it]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 3 \t training loss: \t 0.5311810686474755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [04:48<00:00, 13.75s/it]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 4 \t training loss: \t 0.5071042321977162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [04:52<00:00, 13.95s/it]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 5 \t training loss: \t 0.4743643417244866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [04:51<00:00, 13.87s/it]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 6 \t training loss: \t 0.48019560887700036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [04:50<00:00, 13.84s/it]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 7 \t training loss: \t 0.4175508462247394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [04:53<00:00, 13.98s/it]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 8 \t training loss: \t 0.4053116483347757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [04:56<00:00, 14.12s/it]\n",
      "  0%|          | 0/21 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 9 \t training loss: \t 0.3855597291673933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [04:58<00:00, 14.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: \t 10 \t training loss: \t 0.38759595794337137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Training the Model\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# batch size of the model\n",
    "batch_size = 64\n",
    "\n",
    "# number of epochs to train the model\n",
    "n_epochs = 10\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    train_loss = 0.0\n",
    "        \n",
    "    permutation = torch.randperm(final_train.size()[0])\n",
    "\n",
    "    training_loss = []\n",
    "    for i in tqdm(range(0,final_train.size()[0], batch_size)):\n",
    "\n",
    "        indices = permutation[i:i+batch_size]\n",
    "        batch_x, batch_y = final_train[indices], final_train_label[indices]\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            batch_x, batch_y = batch_x.cpu(), batch_y.cpu()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_x)\n",
    "        loss = criterion(outputs,batch_y)\n",
    "\n",
    "        training_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    training_loss = np.average(training_loss)\n",
    "    print('epoch: \\t', epoch, '\\t training loss: \\t', training_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNN_model = torch.load('model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [02:01<00:00,  5.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracy: \t 0.836656746031746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "# prediction for training set\n",
    "predict = []\n",
    "target = []\n",
    "permutation_train = torch.randperm(final_train.size()[0])\n",
    "for i in tqdm(range(0,final_train.size()[0], batch_size)):\n",
    "    index = permutation_train[i:i+batch_size]\n",
    "    batch_x, batch_y = final_train[index], final_train_label[index]\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        batch_x, batch_y = batch_x.cpu(), batch_y.cpu()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(batch_x.cpu())\n",
    "\n",
    "    softmax = torch.exp(output).cpu()\n",
    "    prob = list(softmax.numpy())\n",
    "    prediction = np.argmax(prob, axis=1)\n",
    "    predict.append(prediction)\n",
    "    target.append(batch_y)\n",
    "    \n",
    "# training accuracy\n",
    "accuracy = []\n",
    "for i in range(len(predict)):\n",
    "    accuracy.append(accuracy_score(target[i].cpu(),predict[i]))\n",
    "    \n",
    "print('training accuracy: \\t', np.average(accuracy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8153846153846154"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the performance on validation set\n",
    "torch.manual_seed(0)\n",
    "output = model(val_x.cpu())\n",
    "softmax = torch.exp(output).cpu()\n",
    "prob = list(softmax.detach().numpy())\n",
    "predict = np.argmax(prob, axis=1)\n",
    "accuracy_score(val_y, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0) / 0\n",
      "tensor(1) / 1\n",
      "tensor(0) / 1\n",
      "tensor(0) / 0\n",
      "tensor(0) / 0\n",
      "tensor(1) / 1\n",
      "tensor(0) / 0\n",
      "tensor(1) / 1\n",
      "tensor(0) / 0\n",
      "tensor(1) / 1\n",
      "tensor(0) / 0\n",
      "tensor(0) / 0\n",
      "tensor(1) / 0\n",
      "tensor(0) / 0\n",
      "tensor(0) / 0\n",
      "tensor(1) / 1\n",
      "tensor(1) / 1\n",
      "tensor(0) / 0\n",
      "tensor(1) / 1\n",
      "tensor(1) / 1\n",
      "tensor(0) / 0\n",
      "tensor(1) / 0\n",
      "tensor(1) / 1\n",
      "tensor(0) / 0\n",
      "tensor(1) / 1\n",
      "tensor(0) / 0\n",
      "tensor(0) / 0\n",
      "tensor(0) / 1\n",
      "tensor(0) / 0\n",
      "tensor(1) / 1\n",
      "tensor(0) / 1\n",
      "tensor(0) / 0\n",
      "tensor(1) / 1\n",
      "tensor(1) / 1\n",
      "tensor(0) / 0\n",
      "tensor(1) / 1\n",
      "tensor(0) / 0\n",
      "tensor(0) / 0\n",
      "tensor(0) / 0\n",
      "tensor(0) / 0\n",
      "tensor(1) / 1\n",
      "tensor(0) / 0\n",
      "tensor(1) / 1\n",
      "tensor(1) / 1\n",
      "tensor(1) / 1\n",
      "tensor(1) / 0\n",
      "tensor(0) / 1\n",
      "tensor(1) / 0\n",
      "tensor(1) / 1\n",
      "tensor(1) / 1\n",
      "tensor(1) / 1\n",
      "tensor(0) / 0\n",
      "tensor(1) / 1\n",
      "tensor(0) / 0\n",
      "tensor(0) / 1\n",
      "tensor(1) / 0\n",
      "tensor(0) / 0\n",
      "tensor(1) / 1\n",
      "tensor(0) / 1\n",
      "tensor(0) / 1\n",
      "tensor(0) / 0\n",
      "tensor(1) / 1\n",
      "tensor(1) / 1\n",
      "tensor(1) / 1\n",
      "tensor(1) / 1\n"
     ]
    }
   ],
   "source": [
    "#print(accuracy_score(target[i].cpu(),prediction[i]))\n",
    "v=accuracy_score(val_y, predict)\n",
    "for i, j in zip(val_y, predict):\n",
    "    print(str(i) + \" / \" + str(j))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
